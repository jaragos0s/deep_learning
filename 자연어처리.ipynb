{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1_M9kLecg6wjcJY3rfeJzvWAeqSkLwiH0",
      "authorship_tag": "ABX9TyO7dzQGNW4wPPCPkNSX8Jie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaragos0s/deep_learning/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFm--jcXWi60"
      },
      "source": [
        "핸즈온 머신러닝 \r\n",
        "#Chapter16. RNN과 어텐션을 사용한 자연어 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN5XzSy7cANj",
        "outputId": "e0ded365-e565-4bdc-a219-ac9a2be870d4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIRtfs83XhMp"
      },
      "source": [
        "##Char-RNN을 사용해 셰익스피어 문체 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBY3AtOrYF9R"
      },
      "source": [
        "import sys\r\n",
        "import sklearn\r\n",
        "assert sklearn.__version__ >= \"0.20\"\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "assert tf.__version__ >= \"2.0\"\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEnp_JOjWcuc"
      },
      "source": [
        "'''작품 다운로드'''\r\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"\r\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\r\n",
        "with open(filepath) as f:\r\n",
        "  shakespeare_text = f.read()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THwZNs5eY0kt",
        "outputId": "e90eb17b-0fef-417d-a68b-a0fca70dc268"
      },
      "source": [
        "print(shakespeare_text[:200])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HltcmYK5ZI4i",
        "outputId": "10b22f17-48b9-4388-fccd-cf60801353a2"
      },
      "source": [
        "'''shakespeare.txt 파일에 어떤 문자가 있는지 sorting 해서 출력'''\r\n",
        "\"\".join(sorted(set(shakespeare_text.lower())))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1pAdu2LZJ_e"
      },
      "source": [
        "''' 모든 글자를 정수로 인코딩 '''\r\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level = True) # char_level = True -> 단어 수준 인코딩(기본적으로 텍스트를 소문자로 바꿈)\r\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujzz2m_nZuFH",
        "outputId": "759c2b73-5e84-41b4-fb49-faa3bb25a6ed"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xn_8_WiZyfb"
      },
      "source": [
        "max_id = len(tokenizer.word_index) # 고유 글자 개수\r\n",
        "dataset_size = tokenizer.document_count # 전체 글자 개수"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfABYsJLZ_Cf"
      },
      "source": [
        "''' 전체 텍스트를 인코딩해 각 글자를 ID로 나타냄 '''\r\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iJlL13gaQSG"
      },
      "source": [
        "### 순차 데이터셋 나누기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gniZw7aaX6N"
      },
      "source": [
        "훈련 세트, 검증 세트, 테스트 세트가 중복되지 않도록 만들어야 한다. \r\n",
        "\r\n",
        "시계열 데이터는 보통 시간에 따라 나눈다. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWOY3AroaUyW"
      },
      "source": [
        "''' 텍스트의 처음 90%를 훈련 세트로 사용 '''\r\n",
        "train_size = dataset_size * 90 // 100\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmMtOchla1aN"
      },
      "source": [
        "### 순차 데이터를 윈도 여러 개로 자르기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak1tIGEvqijP"
      },
      "source": [
        "데이터셋의 window() 메서드를 사용해 긴 시퀀스를 작은, 많은 텍스트 윈도(매우 짧은 부분 문자열)로 변환\r\n",
        "\r\n",
        "RNN은 이 부분 문자열 길이만큼만 역전파를 위해 펼쳐진다. -> TBPTT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGgLjyizaPda"
      },
      "source": [
        "n_steps = 100\r\n",
        "window_length = n_steps + 1 # target = 1글자 앞의 input"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjmM3geFaFrq"
      },
      "source": [
        "dataset = dataset.window(window_length, shift = 1, drop_remainder = True) \r\n",
        "#shift = 1 : 가장 큰 훈련세트를 만듦.\r\n",
        "# drop_remainder = True : 모든 윈도가 동일하게 101개의 글자를 포함하도록 설정"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bB1QtAesNRn"
      },
      "source": [
        "- window() : 각각 하나의 데이터셋으로 표현되는 윈도를 포함하는 데이터셋 생성. -> nested dataset(데이터셋 메서드를 호출하여 각 윈도를 변환할 때 유용)\r\n",
        "\r\n",
        "BUT 모델은 데이터셋이 아니라 \"텐서\"를 기대하기 때문에 훈련에 중첩 데이터셋을 바로 사용할 수 없음 -> flat dadtaset(데이터셋이 들어 있지 않는 데이터셋)으로 변환해야 함. \r\n",
        "\r\n",
        "- flat_map() : 중첩 데이터셋을 평평하게 만들기 전에 각 데이터셋에 적용할 변환 함수를 매개변수로 받을 수 있음. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-48tqjur9hB"
      },
      "source": [
        "dataset = dataset.flat_map(lambda window:window.batch(window_length)) # window_length만큼 읽고 lambda 함수를 적용해 텐서 반환 "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oshnc9Nxt-rL"
      },
      "source": [
        "''' 결과값 유지 위해 시드 설정 '''\r\n",
        "np.random.seed(42)\r\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oEG6hdzuKxf"
      },
      "source": [
        "batch_size = 32\r\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\r\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBHgEbhRutRj"
      },
      "source": [
        "''' 일반적으로 categorical 입력 특성은 one-hot vector 이나 embedding으로 인코딩 '''\r\n",
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth = max_id), Y_batch))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZOZYI_vKMs"
      },
      "source": [
        "# 데이터셋에 필요한 데이터를 미리 불러오기\r\n",
        "''' CPU 연산속도 < 메모리 접근속도 가 되어 CPU가 놀게 되는 비효율적인 현상 방지하기 위해\r\n",
        "    prefetch를 이용해 cache나 main memory에서 데이터를 찾음. '''\r\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GU5d3o-vqDX"
      },
      "source": [
        "### Creating & Training the Char-RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "h2RBv45JvNyO",
        "outputId": "3b9a222f-e69a-48b5-b2d8-b5bed2564652"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\r\n",
        "    keras.layers.GRU(128, return_sequences=True,dropout=0.2, recurrent_dropout=0.2),\r\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\r\n",
        "# label이 정수형일 때 sparse_categorical_crossentropy 사용. \r\n",
        "# label이 one-hot vector일 때에는 categorical_crossentropy 사용\r\n",
        "# 우리는 label을 one-hot-vector로 만든게 아니라서 sparse_categorical_crossentropy로 지정\r\n",
        "\r\n",
        "'''아 짱 오래 걸림...... 오늘 안에 끝날까... 예측 하고 싶은데 ...'''\r\n",
        "\r\n",
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'아 짱 오래 걸림...... 오늘 안에 끝날까... 예측 하고 싶은데 ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b5gHCRkxoGt"
      },
      "source": [
        "### Char-RNN 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQpJGbGdxHw1"
      },
      "source": [
        "'''전처리'''\r\n",
        "def preprocess(texts):\r\n",
        "  X = np.array(tokenizer.texts_to_sequences(texts)) - 1\r\n",
        "  return tf.one_hot(X, max_id)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMskfBhvx7BF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b140ad0f-2442-41f0-e915-7762f2ae093f"
      },
      "source": [
        "X_new = preprocess[(\"I love yo\")]\r\n",
        "Y_pred = model.predict_classes(X_new)\r\n",
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫번째 문장, 마지막 글자"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-91614137e441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I love yo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 첫번째 문장, 마지막 글자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pei7glwn1Rbc"
      },
      "source": [
        "### 가짜 셰익스피어 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tng0Q3WyNiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fac5776-0a07-48a8-eaf3-15d1dab1fb5f"
      },
      "source": [
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()\n",
        "# we can select next character randomly based on the probablity that model predicts"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "        1, 0, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jstuLbU1POE"
      },
      "source": [
        "def next_char(text, temperature = 1): # control the variety of generated texts\n",
        "  X_new = preprocess([text])\n",
        "  y_proba = model.predict(X_new)[0, -1:, :]\n",
        "  rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "  char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "  return tokenizer.sequences_to_texts(char_id.numy())[0]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "569c0Y-qPYEO"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text += next_char(text, temperature)\n",
        "  return text"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVWxKx-FX-f2"
      },
      "source": [
        "### 상태가 있는 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvhlNbYYLPp"
      },
      "source": [
        "RNN이 한 훈련 배치를 처리한 후에 마지막 상태를 다음 훈련 배치의 초기 상태로 사용 \r\n",
        "\r\n",
        "-> 역전파는 짧은 시퀀스에서 일어나지만 모델이 장기간 패턴을 학습할 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W5rcrbI3w-p"
      },
      "source": [
        "순차적이고 겹치지 않는 입력 시퀀스 생성(shift = n_steps) \r\n",
        "-> 하나의 윈도를 갖는 배치를 만들기\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjIrd2zBXfOF"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset = dataset.window(window_length, shift = n_steps, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "dataset = dataset.batch(1)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth= max_id), Y_batch))\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i21t7KlG-ark"
      },
      "source": [
        "batch_size = 32\r\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\r\n",
        "datasets = []\r\n",
        "for encoded_part in encoded_parts:\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\r\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\r\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\r\n",
        "    datasets.append(dataset)\r\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\r\n",
        "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\r\n",
        "dataset = dataset.map(\r\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\r\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kEsYGiR5kb3"
      },
      "source": [
        "1. 각 순환층을 만들 때 stateful = True로 지정\r\n",
        "2. 상태가 있는 RNN은 배치 크기를 알아야 함. -> 첫번째 층에 batch_input_shape 매개변수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7diEE3E4bsg",
        "outputId": "51c5368a-47f3-43f1-b5b3-eee3eae050fc"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "                                 keras.layers.GRU(128, return_sequences=True, stateful = True, \r\n",
        "                                                  dropout = 0.2, recurrent_dropout = 0.2, \r\n",
        "                                                  batch_input_shape = [batch_size, None, max_id]),\r\n",
        "                                 keras.layers.GRU(128, return_sequences=True, stateful = True, \r\n",
        "                                                  dropout = 0.2, recurrent_dropout = 0.2),\r\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\r\n",
        "])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6iIAI6p5gBP"
      },
      "source": [
        "#epoch 끝마다 텍스트를 다시 시작하기 전에 상태 재설정\r\n",
        "class ResetStatesCallback(keras.callbacks.Callback):\r\n",
        "  def on_epoch_begin(self, epoch, logs):\r\n",
        "    self.model.reset_states()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PWxuTqp6Bpv",
        "outputId": "fdbf6bf8-d8a8-45be-f154-8ee07a22fb37"
      },
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"adam\")\r\n",
        "steps_per_epoch = train_size // batch_size // n_steps\r\n",
        "history = model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs = 50, callbacks=[ResetStatesCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 76s 236ms/step - loss: 2.8978\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 76s 242ms/step - loss: 2.2689\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 2.5783\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 78s 250ms/step - loss: 2.6874\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 78s 249ms/step - loss: 2.4219\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 76s 242ms/step - loss: 2.0524\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 78s 249ms/step - loss: 2.0933\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 2.1620\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 78s 248ms/step - loss: 2.3065\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 77s 247ms/step - loss: 2.2710\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 76s 244ms/step - loss: 2.2148\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 76s 244ms/step - loss: 2.1615\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 2.1183\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 79s 252ms/step - loss: 2.0815\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 2.0470\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 78s 250ms/step - loss: 2.0185\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 75s 241ms/step - loss: 1.9963\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 78s 250ms/step - loss: 1.9746\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 1.9525\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 79s 252ms/step - loss: 1.9354\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 1.9132\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 76s 244ms/step - loss: 1.8934\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 1.8779\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 75s 238ms/step - loss: 1.8596\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 74s 236ms/step - loss: 1.8422\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 75s 239ms/step - loss: 1.8243\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 74s 236ms/step - loss: 1.8074\n",
            "Epoch 28/50\n",
            "225/313 [====================>.........] - ETA: 21s - loss: 1.7923"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BBimLk6S_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}