{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS231n_Lecture8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaTwRo7McDbfn0TX0vzo/U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdTlkAKkabio"
      },
      "source": [
        "# Lecture 8  Deep Learning Software"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tlc2VQO-rrD"
      },
      "source": [
        "## Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Tg04ptaWJj"
      },
      "source": [
        "# Computational Graphs\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "N, D = 3, 4\n",
        "\n",
        "x = np.random.randn(N, D)\n",
        "y = np.random.randn(N, D)\n",
        "z = np.random.randn(N, D)\n",
        "\n",
        "a = x * y\n",
        "b = a + z\n",
        "c = np.sum(b)\n",
        "\n",
        "grad_c = 1.0\n",
        "grad_b = grad_c * np.ones((N, D))\n",
        "grad_a = grad_b.copy()\n",
        "grad_z = grad_b.copy()\n",
        "grad_x = grad_a * y\n",
        "grad_y = grad_a * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjvjdvbX9nlH"
      },
      "source": [
        "## Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "j3MJJn1G9OOc",
        "outputId": "f4beeb2f-4135-4aa1-d70b-38bdbc09027f"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import tensorflow as tf\n",
        "\n",
        "N, D = 3000, 4000\n",
        "''' \n",
        "# Tensorflow 1.6 version\n",
        "with tf.device('/gpu:0'):\n",
        "  x = tf.placeholder(tf.float32)\n",
        "  y = tf.placeholder(tf.float32)\n",
        "  z = tf.placeholder(tf.float32)\n",
        "\n",
        "  a = x * y\n",
        "  b = a + z\n",
        "  c = tf.reduce_sum(b)\n",
        "\n",
        "grad_x, grad_y, grad_z = tf.gradients(c, [x, y, z])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  values = {\n",
        "      x: np.random.randn(N, D),\n",
        "      y: np.random.randn(N, D),\n",
        "      z: np.random.randn(N, D)\n",
        "  }\n",
        "  out = sess.run([c, grad_x, grad_y, grad_z],\n",
        "             feed_dict = values)\n",
        "  c_val, grad_x_val, grad_y_val, grad_z_val = out\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" \\n# Tensorflow 1.6 version\\nwith tf.device('/gpu:0'):\\n  x = tf.placeholder(tf.float32)\\n  y = tf.placeholder(tf.float32)\\n  z = tf.placeholder(tf.float32)\\n\\n  a = x * y\\n  b = a + z\\n  c = tf.reduce_sum(b)\\n\\ngrad_x, grad_y, grad_z = tf.gradients(c, [x, y, z])\\n\\nwith tf.Session() as sess:\\n  values = {\\n      x: np.random.randn(N, D),\\n      y: np.random.randn(N, D),\\n      z: np.random.randn(N, D)\\n  }\\n  out = sess.run([c, grad_x, grad_y, grad_z],\\n             feed_dict = values)\\n  c_val, grad_x_val, grad_y_val, grad_z_val = out\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBMD84t0_6D0"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1_cfkkJ_AC3",
        "outputId": "2c63cd93-395a-4b3b-eb26-96e25497fdb0"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "N, D = 3, 4\n",
        "\n",
        "x = Variable(torch.randn(N, D), requires_grad = True)\n",
        "y = Variable(torch.randn(N, D), requires_grad = True)\n",
        "z = Variable(torch.randn(N, D), requires_grad = True)\n",
        "\n",
        "a = x * y\n",
        "b = a + z\n",
        "c = torch.sum(b)\n",
        "\n",
        "# computes all gradients\n",
        "c.backward()\n",
        "\n",
        "print(x.grad.data)\n",
        "print(y.grad.data)\n",
        "print(z.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9877,  0.0456,  0.3350,  0.5279],\n",
            "        [ 0.8590,  1.6820, -1.4755, -0.9407],\n",
            "        [ 0.9549, -0.3822,  0.4878, -0.2568]])\n",
            "tensor([[ 0.9742,  0.2109,  0.6860,  1.9508],\n",
            "        [-0.9324, -1.4801, -0.7895,  0.5620],\n",
            "        [-1.7452,  3.0810, -1.1070,  1.1661]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLukKrwlAlrV"
      },
      "source": [
        "## TensorFlow: Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOh7RnH4AlOM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "6546fde6-37a8-4897-eff7-6838dce638fb"
      },
      "source": [
        "# Train a two-layer ReLU network on random data with L2 loss\n",
        "\n",
        "'''\n",
        "# Define computational graph\n",
        "N, D, H = 64, 1000, 100\n",
        "x = tf.placeholder(tf.float32, shape(N, D))\n",
        "y = tf.placeholder(tf.float32, shape(N, D))\n",
        "w1 = tf.placeholder(tf.float32, shape(D, H))\n",
        "w2 = tf.placeholder(tf.float32, shape(H, D))\n",
        "\n",
        "# Forward pass\n",
        "h = tf.maximum(tf.matmul(x, w1), 0)\n",
        "y_pred = tf.matmul(h, w2)\n",
        "diff = y_pred - y\n",
        "#L2 Euclidean Loss\n",
        "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis = 1))\n",
        "\n",
        "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
        "\n",
        "# add assign operations to update w1 and w2 as part of the graph\n",
        "learning_rate = 1e-5\n",
        "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
        "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
        "# Run the graph many times  \n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  values = {\n",
        "      x: np.random.randn(N, D),\n",
        "      w1: np.random.randn(D, H),\n",
        "      w2: np.random.randn(H, d),\n",
        "      y: np.random.randn(N, D) }\n",
        "  \n",
        "  out= sess.run([loss, grad_w1, grad_w2],\n",
        "                feed_dict = values)\n",
        "  loss_val, grad_w1_val, grad_w2_val = out\n",
        "'''  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Define computational graph\\nN, D, H = 64, 1000, 100\\nx = tf.placeholder(tf.float32, shape(N, D))\\ny = tf.placeholder(tf.float32, shape(N, D))\\nw1 = tf.placeholder(tf.float32, shape(D, H))\\nw2 = tf.placeholder(tf.float32, shape(H, D))\\n\\n# Forward pass\\nh = tf.maximum(tf.matmul(x, w1), 0)\\ny_pred = tf.matmul(h, w2)\\ndiff = y_pred - y\\n#L2 Euclidean Loss\\nloss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis = 1))\\n\\ngrad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\\n\\n# add assign operations to update w1 and w2 as part of the graph\\nlearning_rate = 1e-5\\nnew_w1 = w1.assign(w1 - learning_rate * grad_w1)\\nnew_w2 = w2.assign(w2 - learning_rate * grad_w2)\\n# Run the graph many times  \\nwith tf.Session() as sess:\\n  sess.run(tf.global_variables_initializer())\\n  values = {\\n      x: np.random.randn(N, D),\\n      w1: np.random.randn(D, H),\\n      w2: np.random.randn(H, d),\\n      y: np.random.randn(N, D) }\\n  \\n  out= sess.run([loss, grad_w1, grad_w2],\\n                feed_dict = values)\\n  loss_val, grad_w1_val, grad_w2_val = out\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji1F-JzsAXJ0"
      },
      "source": [
        "# TensorFlow : Optimizer\n",
        "'''\n",
        "# Define computational graph\n",
        "N, D, H = 64, 1000, 100\n",
        "x = tf.placeholder(tf.float32, shape(N, D))\n",
        "y = tf.placeholder(tf.float32, shape(N, D))\n",
        "w1 = tf.placeholder(tf.float32, shape(D, H))\n",
        "w2 = tf.placeholder(tf.float32, shape(H, D))\n",
        "\n",
        "# Forward pass\n",
        "h = tf.maximum(tf.matmul(x, w1), 0)\n",
        "y_pred = tf.matmul(h, w2)\n",
        "diff = y_pred - y\n",
        "#L2 Euclidean Loss\n",
        "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis = 1))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
        "updates = optimizer.minimize(loss)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  values = {\n",
        "      x: np.random.randn(N, D),\n",
        "      y: np.random.randn(N, D) }\n",
        "  losses = []\n",
        "  for t in range(50):\n",
        "    \n",
        "  loss_val, _ = sess.run([loss, updates],\n",
        "                feed_dict = values)\n",
        "'''  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvS--5spoEpQ"
      },
      "source": [
        "'''\n",
        "N, D, H = 64, 1000, 100\n",
        "x = tf.placeholder(tf.float32, shape(N, D))\n",
        "y = tf.placeholder(tf.float32, shape(N, D))\n",
        "init = tf.contrib.layers.xavier_initializer() # use Xavier initializer\n",
        "h = tf.layers.dense(inputs = x, units = H, activation = tf.nn.relu, kernel_initializer = init)\n",
        "y_pred = tf.layers.dense(inputs = h, units = D, kernel_initializer = init)\n",
        "\n",
        "loss = tf.losses.mean_squared_error(y_pred, y)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(1e0)\n",
        "updates = optimizer.minimize(loss)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  values = { x: np.random.randn(N, D),\n",
        "             y: np.random.randn(N, D)}\n",
        "    for t in range(50):\n",
        "      loss_val, _ = sess.run([loss, updates],\n",
        "                feed_dict = values)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ehyqz3TPpZSW",
        "outputId": "34336cb8-6035-4d55-a6d2-e828c842eb24"
      },
      "source": [
        "# Keras : High-Level-wrapper\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "'''\n",
        "N, D, H = 64, 1000, 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim = D, output_dim = H))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(input_dim = H, output_dim = D))\n",
        "\n",
        "optimizer = SGD(lr = 1e0)\n",
        "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
        "\n",
        "x = np.random.randn(N, D)\n",
        "y = np.random.randn(N, D)\n",
        "history = model.fit(x, y, nb_epoch = 50,\n",
        "                    batch_size = N, verbose = 0)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nN, D, H = 64, 1000, 100\\n\\nmodel = Sequential()\\nmodel.add(Dense(input_dim = D, output_dim = H))\\nmodel.add(Activation('relu'))\\nmodel.add(Dense(input_dim = H, output_dim = D))\\n\\noptimizer = SGD(lr = 1e0)\\nmodel.compile(loss = 'mean_squared_error', optimizer = optimizer)\\n\\nx = np.random.randn(N, D)\\ny = np.random.randn(N, D)\\nhistory = model.fit(x, y, nb_epoch = 50,\\n                    batch_size = N, verbose = 0)\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6EZ22PNqCge"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}