{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS231n_lecture12.ipynb","provenance":[],"authorship_tag":"ABX9TyP+eAkqjxiRy0KYWcUSOBix"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5FGjtJj66y3H"},"source":["# Lecture 12 Visualizing and Understanding"]},{"cell_type":"markdown","metadata":{"id":"Lzm7xOUOBDl2"},"source":["**Gradient Ascent** : Generate a synthetic image that maximally activates a neuron"]},{"cell_type":"markdown","metadata":{"id":"FD8nvsLkWkGy"},"source":["$$ arg max_{I} S_c(I) - \\lambda ||I||_2^2 $$"]},{"cell_type":"markdown","metadata":{"id":"kiDLoTpTZupJ"},"source":["**Deep Dream** : Amplify existing features"]},{"cell_type":"code","metadata":{"id":"Hp4Q0t2B6oFJ"},"source":["def objective_L2(det):\n","   det.diff[:] = det.data\n","  \n","def make_step(net, step_size = 1.5, end = 'inception_4c/output', \n","              jitter = 32, clip = True, objective = objective_L2):\n","  arc = net.blobs['data'] # input image is stored in net's 'data' blob\n","  det = net.blobs[end]\n","\n","  ox, oy = np.random.randint(-jitter, jitter+1, 2)\n","  arc.data[0] = np.roll(np.roll(arc.data[0], ox, -1), oy, -2) # apply jitter shift\n","\n","  net.forward(end = end)\n","  objective(det)  # specify the optimization objective\n","  net.backward(start = end)\n","  q = arc.diff[0]\n","\n","  # apply normailzed ascent step to the input image\n","  arc.data[:] += np.rall(np.roll(arc.data[0], -ox, -1), -oy, -2) # unshift image\n","\n","  if clip:\n","    bias = net.transformer.mean['data']\n","    arc.data[:] = np.clip(arc, data, -bias, 255-bias)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"viNxGwEPugXx"},"source":["**Gram Matrix** \n","\n","Each Layer of CNN gives C x H x W tensor of features; HxW grid of C-dimensional vectors\n","Outer product of two C-dimensional vectors gives C x C matrix measuring co-occurence\n","-> Average over all HW pairs of vectors giving \"Gram Matrix\"  of shape C x C\n","\n","- Efficient to compute\n","- Nice to Texture"]},{"cell_type":"markdown","metadata":{"id":"LsWKq-8vvkWy"},"source":["**Neural Texture Synthesis**\n","1. Pretrain a CNN on ImageNet(VGG-19)\n","2. Run input texture forward through CNN, record activations on every layer; layer i gives feature map of shape C_i x H_i x W_i\n","3. At each layer compute the *Gram Matrix* giving outer product of features:\n","$$ G_{ij}^l = \\sum_{k}F_{ik}^lF_{jk}^l$$\n","4. Initialize generated image from random noise\n","5. Pass generated image through CNN, compute Gram matrix on each layer\n","6. Compute loss: weighted sum of L2 distance between Gram matrices\n","7. Backprop to get gradient on image\n","8. Make gradient step on image\n","9. GOTO 5\n"]},{"cell_type":"markdown","metadata":{"id":"NRFqF4PAyPPl"},"source":[""]}]}